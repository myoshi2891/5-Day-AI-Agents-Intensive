{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport time\nimport vertexai\nfrom kaggle_secrets import UserSecretsClient\nfrom vertexai import agent_engines\n\nprint(\"✅ Imports completed successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up Cloud Credentials in Kaggle\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\nprint(\"✅ Cloud credentials configured\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Set your PROJECT_ID\n# PROJECT_ID = \"\"  # TODO: Replace with your project ID\nPROJECT_ID = UserSecretsClient().get_secret(\"PROJECT_ID\")\n\nos.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n\nif PROJECT_ID == \"your-project-id\" or not PROJECT_ID:\n    raise ValueError(\"⚠️ Please replace 'your-project-id' with your actual Google Cloud Project ID.\")\n\nprint(f\"✅ Project ID set to: {PROJECT_ID}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Create simple agent - all code for the agent will live in this directory\n!mkdir -p sample_agent\n\nprint(f\"✅ Sample Agent directory created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile sample_agent/requirements.txt\n\ngoogle-adk\nopentelemetry-instrumentation-google-genai","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile sample_agent/.env\n\n# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations#global-endpoint\nGOOGLE_CLOUD_LOCATION=\"global\"\n\n# Set to 1 to use Vertex AI, or 0 to use Google AI Studio\nGOOGLE_GENAI_USE_VERTEXAI=1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile sample_agent/agent.py\nfrom google.adk.agents import Agent\nimport vertexai\nimport os\n\nvertexai.init(\n    project=os.environ[\"GOOGLE_CLOUD_PROJECT\"],\n    location=os.environ[\"GOOGLE_CLOUD_LOCATION\"],\n)\n\ndef get_weather(city: str) -> dict:\n    \"\"\"\n    Returns weather information for a given city.\n\n    This is a TOOL that the agent can call when users ask about weather.\n    In production, this would call a real weather API (e.g., OpenWeatherMap).\n    For this demo, we use mock data.\n\n    Args:\n        city: Name of the city (e.g., \"Tokyo\", \"New York\")\n\n    Returns:\n        dict: Dictionary with status and weather report or error message\n    \"\"\"\n    # Mock weather database with structured responses\n    weather_data = {\n        \"san francisco\": {\"status\": \"success\", \"report\": \"The weather in San Francisco is sunny with a temperature of 72°F (22°C).\"},\n        \"new york\": {\"status\": \"success\", \"report\": \"The weather in New York is cloudy with a temperature of 65°F (18°C).\"},\n        \"london\": {\"status\": \"success\", \"report\": \"The weather in London is rainy with a temperature of 58°F (14°C).\"},\n        \"tokyo\": {\"status\": \"success\", \"report\": \"The weather in Tokyo is clear with a temperature of 70°F (21°C).\"},\n        \"paris\": {\"status\": \"success\", \"report\": \"The weather in Paris is partly cloudy with a temperature of 68°F (20°C).\"}\n    }\n\n    city_lower = city.lower()\n    if city_lower in weather_data:\n        return weather_data[city_lower]\n    else:\n        available_cities = \", \".join([c.title() for c in weather_data.keys()])\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Weather information for '{city}' is not available. Try: {available_cities}\"\n        }\n\nroot_agent = Agent(\n    name=\"weather_assistant\",\n    model=\"gemini-2.5-flash-lite\",  # Fast, cost-effective Gemini model\n    description=\"A helpful weather assistant that provides weather information for cities.\",\n    instruction=\"\"\"\n    You are a friendly weather assistant. When users ask about the weather:\n\n    1. Identify the city name from their question\n    2. Use the get_weather tool to fetch current weather information\n    3. Respond in a friendly, conversational tone\n    4. If the city isn't available, suggest one of the available cities\n\n    Be helpful and concise in your responses.\n    \"\"\",\n    tools=[get_weather]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile sample_agent/.agent_engine_config.json\n{\n    \"min_instances\": 0,\n    \"max_instances\": 1,\n    \"resource_limits\": {\"cpu\": \"1\", \"memory\": \"1Gi\"}\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"regions_list = [\"europe-west1\", \"europe-west4\", \"us-east4\", \"us-west1\"]\ndeployed_region = random.choice(regions_list)\n\nprint(f\"✅ Selected deployment region: {deployed_region}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip show google-adk","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!adk deploy agent_engine --project=$PROJECT_ID --region=$deployed_region sample_agent --agent_engine_config_file=sample_agent/.agent_engine_config.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize Vertex AI\nvertexai.init(project=PROJECT_ID, location=deployed_region)\n\n# Get the most recently deployed agent\nagents_list = list(agent_engines.list())\nif agents_list:\n    remote_agent = agents_list[0]  # Get the first (most recent) agent\n    client = agent_engines\n    print(f\"✅ Connected to deployed agent: {remote_agent.resource_name}\")\nelse:\n    print(\"❌ No agents found. Please deploy first.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"async for item in remote_agent.async_stream_query(\n    message=\"What is the weather in Tokyo?\",\n    user_id=\"user_42\",\n):\n    print(item)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent_engines.delete(resource_name=remote_agent.resource_name, force=True)\n\nprint(\"✅ Agent successfully deleted\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Setup and authentication complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n\n# Gets the proxied URL in the Kaggle Notebooks environment\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0][\"base_url\"]\n\n    try:\n        path_parts = baseURL.split(\"/\")\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!adk create home_automation_agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile home_automation_agent/agent.py\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\n\nfrom google.genai import types\n\n# Configure Model Retry on errors\nretry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)\n\ndef set_device_status(location: str, device_id: str, status: str) -> dict:\n    \"\"\"Sets the status of a smart home device.\n\n    Args:\n        location: The room where the device is located.\n        device_id: The unique identifier for the device.\n        status: The desired status, either 'ON' or 'OFF'.\n\n    Returns:\n        A dictionary confirming the action.\n    \"\"\"\n    print(f\"Tool Call: Setting {device_id} in {location} to {status}\")\n    return {\n        \"success\": True,\n        \"message\": f\"Successfully set the {device_id} in {location} to {status.lower()}.\"\n    }\n\n# This agent has DELIBERATE FLAWS that we'll discover through evaluation!\nroot_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"home_automation_agent\",\n    description=\"An agent to control smart devices in a home.\",\n    instruction=\"\"\"You are a home automation assistant. You control ALL smart devices in the house.\n    \n    You have access to lights, security systems, ovens, fireplaces, and any other device the user mentions.\n    Always try to be helpful and control whatever device the user asks for.\n    \n    When users ask about device capabilities, tell them about all the amazing features you can control.\"\"\",\n    tools=[set_device_status],\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"url_prefix = get_adk_proxy_url()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!adk web --url_prefix {url_prefix}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# Create evaluation configuration with basic criteria\neval_config = {\n    \"criteria\": {\n        \"tool_trajectory_avg_score\": 1.0,  # Perfect tool usage required\n        \"response_match_score\": 0.8,  # 80% text similarity threshold\n    }\n}\n\nwith open(\"home_automation_agent/test_config.json\", \"w\") as f:\n    json.dump(eval_config, f, indent=2)\n\nprint(\"‚úÖ Evaluation configuration created!\")\nprint(\"\\nüìä Evaluation Criteria:\")\nprint(\"‚Ä¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match\")\nprint(\"‚Ä¢ response_match_score: 0.8 - Requires 80% text similarity\")\nprint(\"\\nüéØ What this evaluation will catch:\")\nprint(\"‚úÖ Incorrect tool usage (wrong device, location, or status)\")\nprint(\"‚úÖ Poor response quality and communication\")\nprint(\"‚úÖ Deviations from expected behavior patterns\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create evaluation test cases that reveal tool usage and response quality problems\ntest_cases = {\n    \"eval_set_id\": \"home_automation_integration_suite\",\n    \"eval_cases\": [\n        {\n            \"eval_id\": \"living_room_light_on\",\n            \"conversation\": [\n                {\n                    \"user_content\": {\n                        \"parts\": [\n                            {\"text\": \"Please turn on the floor lamp in the living room\"}\n                        ]\n                    },\n                    \"final_response\": {\n                        \"parts\": [\n                            {\n                                \"text\": \"Successfully set the floor lamp in the living room to on.\"\n                            }\n                        ]\n                    },\n                    \"intermediate_data\": {\n                        \"tool_uses\": [\n                            {\n                                \"name\": \"set_device_status\",\n                                \"args\": {\n                                    \"location\": \"living room\",\n                                    \"device_id\": \"floor lamp\",\n                                    \"status\": \"ON\",\n                                },\n                            }\n                        ]\n                    },\n                }\n            ],\n        },\n        {\n            \"eval_id\": \"kitchen_on_off_sequence\",\n            \"conversation\": [\n                {\n                    \"user_content\": {\n                        \"parts\": [{\"text\": \"Switch on the main light in the kitchen.\"}]\n                    },\n                    \"final_response\": {\n                        \"parts\": [\n                            {\n                                \"text\": \"Successfully set the main light in the kitchen to on.\"\n                            }\n                        ]\n                    },\n                    \"intermediate_data\": {\n                        \"tool_uses\": [\n                            {\n                                \"name\": \"set_device_status\",\n                                \"args\": {\n                                    \"location\": \"kitchen\",\n                                    \"device_id\": \"main light\",\n                                    \"status\": \"ON\",\n                                },\n                            }\n                        ]\n                    },\n                }\n            ],\n        },\n    ],\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open(\"home_automation_agent/integration.evalset.json\", \"w\") as f:\n    json.dump(test_cases, f, indent=2)\n\nprint(\"‚úÖ Evaluation test cases created\")\nprint(\"\\nüß™ Test scenarios:\")\nfor case in test_cases[\"eval_cases\"]:\n    user_msg = case[\"conversation\"][0][\"user_content\"][\"parts\"][0][\"text\"]\n    print(f\"‚Ä¢ {case['eval_id']}: {user_msg}\")\n\nprint(\"\\nüìä Expected results:\")\nprint(\"‚Ä¢ basic_device_control: Should pass both criteria\")\nprint(\n    \"‚Ä¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters\"\n)\nprint(\n    \"‚Ä¢ poor_response_quality_test: May fail response_match if response differs too much\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"üöÄ Run this command to execute evaluation:\")\n!adk eval home_automation_agent home_automation_agent/integration.evalset.json --config_file_path=home_automation_agent/test_config.json --print_detailed_results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyzing evaluation results - the data science approach\nprint(\"üìä Understanding Evaluation Results:\")\nprint()\nprint(\"üîç EXAMPLE ANALYSIS:\")\nprint()\nprint(\"Test Case: living_room_light_on\")\nprint(\"  ‚ùå response_match_score: 0.45/0.80\")\nprint(\"  ‚úÖ tool_trajectory_avg_score: 1.0/1.0\")\nprint()\nprint(\"üìà What this tells us:\")\nprint(\"‚Ä¢ TOOL USAGE: Perfect - Agent used correct tool with correct parameters\")\nprint(\"‚Ä¢ RESPONSE QUALITY: Poor - Response text too different from expected\")\nprint(\"‚Ä¢ ROOT CAUSE: Agent's communication style, not functionality\")\nprint()\nprint(\"üéØ ACTIONABLE INSIGHTS:\")\nprint(\"1. Technical capability works (tool usage perfect)\")\nprint(\"2. Communication needs improvement (response quality failed)\")\nprint(\"3. Fix: Update agent instructions for clearer language or constrained response.\")\nprint()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}